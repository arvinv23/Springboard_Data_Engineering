{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5af8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark)\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812366 sha256=82faf4f43ef13c44e548fcbd64406c9eca9c93b173b4bcf97713a349f1ca0176\n",
      "  Stored in directory: /Users/aravindh/Library/Caches/pip/wheels/9d/29/ee/3a756632ca3f0a6870933bac1c9db6e4af2c068f019aba0ee1\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5049fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, sum, min, max\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11bfece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/path/to/spark/python\")\n",
    "sys.path.append(\"/path/to/spark/python/lib/py4j-<version>-src.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c297627",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/15 20:15:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BankingAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ba0439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the dataset\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"surname\", StringType(), True),\n",
    "    StructField(\"credit_score\", IntegerType(), True),\n",
    "    StructField(\"geography\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"tenure\", IntegerType(), True),\n",
    "    StructField(\"balance\", DoubleType(), True),\n",
    "    StructField(\"num_of_products\", IntegerType(), True),\n",
    "    StructField(\"has_credit_card\", IntegerType(), True),\n",
    "    StructField(\"estimated_salary\", DoubleType(), True),\n",
    "    StructField(\"exited\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6c1af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the CSV file into a DataFrame\n",
    "df = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"/Users/aravindh/Desktop/Data Engineering/Azure Mini Project/springboard-pyspark-project/pyspark-project/credit card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe7c439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BankingAnalysis class\n",
    "class BankingAnalysis:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe\n",
    "    \n",
    "    def total_customers(self):\n",
    "        return self.df.count()\n",
    "    \n",
    "    def customers_by_geography(self):\n",
    "        return self.df.groupBy(\"geography\").agg(count(\"*\").alias(\"num_customers\"))\n",
    "    \n",
    "    def customers_by_gender(self):\n",
    "        return self.df.groupBy(\"gender\").agg(count(\"*\").alias(\"num_customers\"))\n",
    "    \n",
    "    def avg_age_by_geography(self):\n",
    "        return self.df.groupBy(\"geography\").agg(avg(\"age\").alias(\"avg_age\"))\n",
    "    \n",
    "    def avg_balance_by_geography(self):\n",
    "        return self.df.groupBy(\"geography\").agg(avg(\"balance\").alias(\"avg_balance\"))\n",
    "    \n",
    "    def min_max_tenure(self):\n",
    "        return self.df.agg(min(\"tenure\").alias(\"min_tenure\"), max(\"tenure\").alias(\"max_tenure\"))\n",
    "    \n",
    "    def num_credit_card_holders(self):\n",
    "        return self.df.filter(col(\"has_credit_card\") == 1).count()\n",
    "    \n",
    "    def avg_salary_by_gender(self):\n",
    "        return self.df.groupBy(\"gender\").agg(avg(\"estimated_salary\").alias(\"avg_salary\"))\n",
    "    \n",
    "    def num_exited_customers(self):\n",
    "        return self.df.filter(col(\"exited\") == 1).count()\n",
    "    \n",
    "    def total_balance(self):\n",
    "        return self.df.agg(sum(\"balance\").alias(\"total_balance\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbf00a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the BankingAnalysis class\n",
    "analysis = BankingAnalysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78ad9f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of customers: 10000\n",
      "Number of customers by geography:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 20:17:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: CreditScore\n",
      " Schema: geography\n",
      "Expected: geography but found: CreditScore\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|geography|num_customers|\n",
      "+---------+-------------+\n",
      "|      829|            8|\n",
      "|      675|           37|\n",
      "|      691|           34|\n",
      "|      467|            4|\n",
      "|      800|           10|\n",
      "|      451|            5|\n",
      "|      666|           38|\n",
      "|      591|           31|\n",
      "|      447|            4|\n",
      "|      574|           21|\n",
      "|      475|            6|\n",
      "|      718|           38|\n",
      "|      613|           42|\n",
      "|      577|           34|\n",
      "|      581|           38|\n",
      "|      544|           25|\n",
      "|      747|           22|\n",
      "|      740|           19|\n",
      "|      647|           31|\n",
      "|      711|           39|\n",
      "+---------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Number of customers by gender:\n",
      "+-------+-------------+\n",
      "| gender|num_customers|\n",
      "+-------+-------------+\n",
      "|Germany|         2509|\n",
      "| France|         5014|\n",
      "|  Spain|         2477|\n",
      "+-------+-------------+\n",
      "\n",
      "Average age by geography:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 20:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Geography\n",
      " Schema: gender\n",
      "Expected: gender but found: Geography\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n",
      "24/09/15 20:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: CreditScore, Gender\n",
      " Schema: geography, age\n",
      "Expected: geography but found: CreditScore\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=22294Kb max_used=22409Kb free=108777Kb\n",
      " bounds [0x00000001041a8000, 0x00000001057b8000, 0x000000010c1a8000]\n",
      " total_blobs=9117 nmethods=8174 adapters=855\n",
      " compilation: disabled (not enough contiguous free space left)\n",
      "+---------+-------+\n",
      "|geography|avg_age|\n",
      "+---------+-------+\n",
      "|      829|   NULL|\n",
      "|      675|   NULL|\n",
      "|      691|   NULL|\n",
      "|      467|   NULL|\n",
      "|      800|   NULL|\n",
      "|      451|   NULL|\n",
      "|      666|   NULL|\n",
      "|      591|   NULL|\n",
      "|      447|   NULL|\n",
      "|      574|   NULL|\n",
      "|      475|   NULL|\n",
      "|      718|   NULL|\n",
      "|      613|   NULL|\n",
      "|      577|   NULL|\n",
      "|      581|   NULL|\n",
      "|      544|   NULL|\n",
      "|      747|   NULL|\n",
      "|      740|   NULL|\n",
      "|      647|   NULL|\n",
      "|      711|   NULL|\n",
      "+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Average balance by geography:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 20:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: CreditScore, Tenure\n",
      " Schema: geography, balance\n",
      "Expected: geography but found: CreditScore\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|geography|       avg_balance|\n",
      "+---------+------------------+\n",
      "|      829|              6.25|\n",
      "|      675| 5.216216216216216|\n",
      "|      691| 5.617647058823529|\n",
      "|      467|               6.5|\n",
      "|      800|               4.5|\n",
      "|      451|               6.6|\n",
      "|      666|4.7105263157894735|\n",
      "|      591| 5.419354838709677|\n",
      "|      447|               5.0|\n",
      "|      574| 4.333333333333333|\n",
      "|      475| 5.333333333333333|\n",
      "|      718|5.2894736842105265|\n",
      "|      613| 5.761904761904762|\n",
      "|      577| 4.823529411764706|\n",
      "|      581| 4.026315789473684|\n",
      "|      544|              5.24|\n",
      "|      747| 5.454545454545454|\n",
      "|      740| 5.473684210526316|\n",
      "|      647| 4.903225806451613|\n",
      "|      711| 5.051282051282051|\n",
      "+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Minimum and maximum tenure: [Row(min_tenure=18, max_tenure=92)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 20:17:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Age\n",
      " Schema: tenure\n",
      "Expected: tenure but found: Age\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n",
      "24/09/15 20:17:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: NumOfProducts\n",
      " Schema: has_credit_card\n",
      "Expected: has_credit_card but found: NumOfProducts\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n",
      "24/09/15 20:17:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Geography, IsActiveMember\n",
      " Schema: gender, estimated_salary\n",
      "Expected: gender but found: Geography\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of credit card holders: 5084\n",
      "Average salary by gender:\n",
      "+-------+-------------------+\n",
      "| gender|         avg_salary|\n",
      "+-------+-------------------+\n",
      "|Germany|0.49740932642487046|\n",
      "| France| 0.5167530913442362|\n",
      "|  Spain| 0.5296729915220024|\n",
      "+-------+-------------------+\n",
      "\n",
      "Number of customers who have exited: 0\n",
      "Total balance across all customers: 50128.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/15 20:17:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: EstimatedSalary\n",
      " Schema: exited\n",
      "Expected: exited but found: EstimatedSalary\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n",
      "24/09/15 20:17:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Tenure\n",
      " Schema: balance\n",
      "Expected: balance but found: Tenure\n",
      "CSV file: file:///Users/aravindh/Desktop/Data%20Engineering/Azure%20Mini%20Project/springboard-pyspark-project/pyspark-project/credit%20card.csv\n"
     ]
    }
   ],
   "source": [
    "# Perform analysis and print the results\n",
    "print(\"Total number of customers:\", analysis.total_customers())\n",
    "print(\"Number of customers by geography:\")\n",
    "analysis.customers_by_geography().show()\n",
    "print(\"Number of customers by gender:\")\n",
    "analysis.customers_by_gender().show()\n",
    "print(\"Average age by geography:\")\n",
    "analysis.avg_age_by_geography().show()\n",
    "print(\"Average balance by geography:\")\n",
    "analysis.avg_balance_by_geography().show()\n",
    "print(\"Minimum and maximum tenure:\", analysis.min_max_tenure().collect())\n",
    "print(\"Number of credit card holders:\", analysis.num_credit_card_holders())\n",
    "print(\"Average salary by gender:\")\n",
    "analysis.avg_salary_by_gender().show()\n",
    "print(\"Number of customers who have exited:\", analysis.num_exited_customers())\n",
    "print(\"Total balance across all customers:\", analysis.total_balance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e91d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
